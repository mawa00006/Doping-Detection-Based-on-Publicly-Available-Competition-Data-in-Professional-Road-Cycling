{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Name              Country            Event  \\\n0    Gina Coello Tache             Honduras         Marathon   \n1       Gregg Tafralis        United States         Shot put   \n2         Teddy Tamgho               France      Triple jump   \n3        William Tanui                Kenya  Middle distance   \n4           Yoel Tapia   Dominican Republic        Sprinting   \n..                 ...                  ...              ...   \n850      Yolanda Osana   Dominican Republic         Hurdling   \n851  Oludamola Osayomi              Nigeria        Sprinting   \n852        Artur Osman               Poland    Long distance   \n853    Hanane Ouhaddou              Morocco     Steeplechase   \n854      Lawretta Ozoh              Nigeria        Sprinting   \n\n    Date of violation Banned substance(s)/Anti-doping rule violation  \\\n0                2001                                     Nandrolone   \n1            19951999                                  Methandienone   \n2                2014                         3 whereabouts failures   \n3                1993                                      Ephedrine   \n4                2012                              Methylhexaneamine   \n..                ...                                            ...   \n850              2012                                     Stanozolol   \n851              2010                              Methylhexaneamine   \n852              2005                                Norandrosterone   \n853              2009                            Biological passport   \n854              2012                                     Stanozolol   \n\n                                   Sanction     Reference(s)  \n0                                   2 years            [216]  \n1    2 years (Reduced from 4 years)Life ban       [184][802]  \n2                                    1 year            [175]  \n3                                       NaN            [648]  \n4                                  6 months        [79][219]  \n..                                      ...              ...  \n850                                 2 years        [25][219]  \n851                                     NaN       [667][674]  \n852                                 2 years            [271]  \n853                                 2 years         [12][14]  \n854                                 2 years  [153][292][676]  \n\n[855 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Country</th>\n      <th>Event</th>\n      <th>Date of violation</th>\n      <th>Banned substance(s)/Anti-doping rule violation</th>\n      <th>Sanction</th>\n      <th>Reference(s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gina Coello Tache</td>\n      <td>Honduras</td>\n      <td>Marathon</td>\n      <td>2001</td>\n      <td>Nandrolone</td>\n      <td>2 years</td>\n      <td>[216]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gregg Tafralis</td>\n      <td>United States</td>\n      <td>Shot put</td>\n      <td>19951999</td>\n      <td>Methandienone</td>\n      <td>2 years (Reduced from 4 years)Life ban</td>\n      <td>[184][802]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Teddy Tamgho</td>\n      <td>France</td>\n      <td>Triple jump</td>\n      <td>2014</td>\n      <td>3 whereabouts failures</td>\n      <td>1 year</td>\n      <td>[175]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>William Tanui</td>\n      <td>Kenya</td>\n      <td>Middle distance</td>\n      <td>1993</td>\n      <td>Ephedrine</td>\n      <td>NaN</td>\n      <td>[648]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Yoel Tapia</td>\n      <td>Dominican Republic</td>\n      <td>Sprinting</td>\n      <td>2012</td>\n      <td>Methylhexaneamine</td>\n      <td>6 months</td>\n      <td>[79][219]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>850</th>\n      <td>Yolanda Osana</td>\n      <td>Dominican Republic</td>\n      <td>Hurdling</td>\n      <td>2012</td>\n      <td>Stanozolol</td>\n      <td>2 years</td>\n      <td>[25][219]</td>\n    </tr>\n    <tr>\n      <th>851</th>\n      <td>Oludamola Osayomi</td>\n      <td>Nigeria</td>\n      <td>Sprinting</td>\n      <td>2010</td>\n      <td>Methylhexaneamine</td>\n      <td>NaN</td>\n      <td>[667][674]</td>\n    </tr>\n    <tr>\n      <th>852</th>\n      <td>Artur Osman</td>\n      <td>Poland</td>\n      <td>Long distance</td>\n      <td>2005</td>\n      <td>Norandrosterone</td>\n      <td>2 years</td>\n      <td>[271]</td>\n    </tr>\n    <tr>\n      <th>853</th>\n      <td>Hanane Ouhaddou</td>\n      <td>Morocco</td>\n      <td>Steeplechase</td>\n      <td>2009</td>\n      <td>Biological passport</td>\n      <td>2 years</td>\n      <td>[12][14]</td>\n    </tr>\n    <tr>\n      <th>854</th>\n      <td>Lawretta Ozoh</td>\n      <td>Nigeria</td>\n      <td>Sprinting</td>\n      <td>2012</td>\n      <td>Stanozolol</td>\n      <td>2 years</td>\n      <td>[153][292][676]</td>\n    </tr>\n  </tbody>\n</table>\n<p>855 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('merged.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests-HTML\r\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\r\n",
      "Collecting pyppeteer>=0.0.14\r\n",
      "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m83.4/83.4 KB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from requests-HTML) (2.27.1)\r\n",
      "Collecting parse\r\n",
      "  Downloading parse-1.19.0.tar.gz (30 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting bs4\r\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting pyquery\r\n",
      "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\r\n",
      "Collecting fake-useragent\r\n",
      "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting w3lib\r\n",
      "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-HTML) (4.63.1)\r\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-HTML) (1.26.9)\r\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-HTML) (4.11.3)\r\n",
      "Collecting appdirs<2.0.0,>=1.4.3\r\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Collecting pyee<9.0.0,>=8.1.0\r\n",
      "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\r\n",
      "Collecting websockets<11.0,>=10.0\r\n",
      "  Downloading websockets-10.3-cp38-cp38-macosx_11_0_arm64.whl (97 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m97.2/97.2 KB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: certifi>=2021 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-HTML) (2021.10.8)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from bs4->requests-HTML) (4.10.0)\r\n",
      "Collecting cssselect>0.7.9\r\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\r\n",
      "Requirement already satisfied: lxml>=2.1 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from pyquery->requests-HTML) (4.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from requests->requests-HTML) (2.0.12)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from requests->requests-HTML) (3.3)\r\n",
      "Requirement already satisfied: six>=1.4.1 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from w3lib->requests-HTML) (1.16.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-HTML) (3.7.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/mattes/tensorflow-test/env/lib/python3.8/site-packages (from beautifulsoup4->bs4->requests-HTML) (2.3.1)\r\n",
      "Building wheels for collected packages: bs4, fake-useragent, parse\r\n",
      "  Building wheel for bs4 (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=6ce7c34ca7db2fa6ca3ad03ea707921b41b979c7050e5e1f9dff83ff3218ff0d\r\n",
      "  Stored in directory: /Users/mattes/Library/Caches/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\r\n",
      "  Building wheel for fake-useragent (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=3d3ac187ed464c559f0c985492a239cca2fa9fb1f3df3a641c946ae9806468d6\r\n",
      "  Stored in directory: /Users/mattes/Library/Caches/pip/wheels/a0/b8/b7/8c942b2c5be5158b874a88195116b05ad124bac795f6665e65\r\n",
      "  Building wheel for parse (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=51f6e2c2dbce5052f7059c8a684801babc360962945cd94da3647304e0b2004c\r\n",
      "  Stored in directory: /Users/mattes/Library/Caches/pip/wheels/e5/33/1f/68392720485b3ecf125a69e700baaab7624616deedea2fa6e2\r\n",
      "Successfully built bs4 fake-useragent parse\r\n",
      "Installing collected packages: pyee, parse, fake-useragent, appdirs, websockets, w3lib, cssselect, pyquery, pyppeteer, bs4, requests-HTML\r\n",
      "Successfully installed appdirs-1.4.4 bs4-0.0.1 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-HTML-0.10.0 w3lib-1.22.0 websockets-10.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests-HTML"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mscrape_rider_all_results\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhttps://www.procyclingstats.com/rider/huub-duijn\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m df\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mscrape_rider_all_results\u001B[0;34m(url)\u001B[0m\n\u001B[1;32m   1171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (url[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m!=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m): url\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1173\u001B[0m \u001B[38;5;66;03m# get years for which results exist\u001B[39;00m\n\u001B[0;32m-> 1174\u001B[0m years\u001B[38;5;241m=\u001B[39m\u001B[43mget_rider_years\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1176\u001B[0m \u001B[38;5;66;03m# fetch data for all years\u001B[39;00m\n\u001B[1;32m   1177\u001B[0m all_results\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mDataFrame()\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mget_rider_years\u001B[0;34m(url)\u001B[0m\n\u001B[1;32m   1022\u001B[0m session\u001B[38;5;241m=\u001B[39mHTMLSession()\n\u001B[1;32m   1023\u001B[0m response\u001B[38;5;241m=\u001B[39msession\u001B[38;5;241m.\u001B[39mget(url)\n\u001B[0;32m-> 1024\u001B[0m \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhtml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1025\u001B[0m soup\u001B[38;5;241m=\u001B[39mBeautifulSoup(response\u001B[38;5;241m.\u001B[39mhtml\u001B[38;5;241m.\u001B[39mhtml,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlxml\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;66;03m# isolate desired table\u001B[39;00m\n",
      "File \u001B[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/requests_html.py:586\u001B[0m, in \u001B[0;36mHTML.render\u001B[0;34m(self, retries, script, wait, scrolldown, sleep, reload, timeout, keep_page)\u001B[0m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m, retries: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m8\u001B[39m, script: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, wait: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m, scrolldown\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, sleep: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, reload: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, timeout: Union[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m8.0\u001B[39m, keep_page: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    542\u001B[0m     \u001B[38;5;124;03m\"\"\"Reloads the response in Chromium, and replaces HTML content\u001B[39;00m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;124;03m    with an updated version, with JavaScript executed.\u001B[39;00m\n\u001B[1;32m    544\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    583\u001B[0m \u001B[38;5;124;03m    Chromium into your home directory (``~/.pyppeteer``).\u001B[39;00m\n\u001B[1;32m    584\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 586\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbrowser \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbrowser\u001B[49m  \u001B[38;5;66;03m# Automatically create a event loop and browser\u001B[39;00m\n\u001B[1;32m    587\u001B[0m     content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;66;03m# Automatically set Reload to False, if example URL is being used.\u001B[39;00m\n",
      "File \u001B[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/requests_html.py:729\u001B[0m, in \u001B[0;36mHTMLSession.browser\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    727\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloop \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mget_event_loop()\n\u001B[1;32m    728\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloop\u001B[38;5;241m.\u001B[39mis_running():\n\u001B[0;32m--> 729\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    730\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_browser \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloop\u001B[38;5;241m.\u001B[39mrun_until_complete(\u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mbrowser)\n\u001B[1;32m    731\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_browser\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead."
     ]
    }
   ],
   "source": [
    "df = scrape_rider_all_results('https://www.procyclingstats.com/rider/huub-duijn')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}